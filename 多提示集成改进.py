import os
import json
import warnings
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from pycocotools.coco import COCO
from groundingdino.util.inference import load_model, load_image, predict
from scipy.optimize import linear_sum_assignment

# --- æŠ‘åˆ¶è­¦å‘Š ---
warnings.filterwarnings("ignore")

# --- é…ç½®è·¯å¾„ ---
COCO_ROOT = r"C:\Users\24344\GroundingDINO\weights\coco\val2017\val_images"
COCO_ANN_FILE = r"C:\Users\24344\GroundingDINO\weights\coco\annotations\annotations_images\instances_val2017.json"

MODEL_CONFIG = r"C:\Users\24344\GroundingDINO\groundingdino\config\GroundingDINO_SwinT_OGC.py"
MODEL_CHECKPOINT = r"C:\Users\24344\GroundingDINO\weights\groundingdino_swint_ogc.pth"

# --- åŠ è½½æ¨¡å‹å’Œæ•°æ®é›† ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model = load_model(MODEL_CONFIG, MODEL_CHECKPOINT, device=device)
coco = COCO(COCO_ANN_FILE)
categories = coco.loadCats(coco.getCatIds())
category_name_to_id = {cat['name'].lower(): cat['id'] for cat in categories}
category_id_to_name = {cat['id']: cat['name'] for cat in categories}

print(f"COCO æ•°æ®é›†ï¼š{len(coco.getImgIds())} å¼ å›¾ç‰‡ï¼Œ{len(categories)} ä¸ªç±»åˆ«")

# --- å®éªŒé…ç½® ---
# æµ‹è¯•3ä¸ªç±»åˆ«
TEST_CATEGORIES = ["person", "car", "chair"]

# æ‰©å±•çš„Prompté›†åˆï¼ˆæ¯ä¸ªç±»åˆ«å¤šä¸ªPromptï¼‰
CATEGORY_MULTI_PROMPTS = {
    "person": [
        "person",  # çº¯åç§°
        "a person",  # ç®€å•æè¿°
        "a photo of a person",  # æ¨¡æ¿
        "a human person",  # è¯¦ç»†æè¿°
        "a person in the image",  # ä¸Šä¸‹æ–‡
        "a person standing",  # åŠ¨ä½œæè¿°
        "human",  # åŒä¹‰è¯
        "people",  # å¤æ•°
        "a man or woman",  # ç»†åˆ†
        "a person walking"  # åŠ¨æ€
    ],
    "car": [
        "car",
        "a car",
        "a photo of a car",
        "a car vehicle",
        "a car on the road",
        "a parked car",
        "vehicle",
        "automobile",
        "a red car",
        "a moving car"
    ],
    "chair": [
        "chair",
        "a chair",
        "a photo of a chair",
        "a chair furniture",
        "a chair in the room",
        "a chair for sitting",
        "seat",
        "furniture",
        "a wooden chair",
        "an office chair"
    ]
}

# èåˆç­–ç•¥é…ç½®
FUSION_STRATEGIES = {
    'max_confidence': 'æœ€å¤§ç½®ä¿¡åº¦èåˆ',
    'weighted_average': 'åŠ æƒå¹³å‡èåˆ',
    'nms': 'NMSèåˆ',
    'wbf': 'WBFèåˆ'
}


# --- åŸºç¡€å‡½æ•° ---
def convert_groundingdino_to_coco(box_np, img_width, img_height):
    """å°† Grounding DINO è¾“å‡ºè½¬æ¢ä¸º COCO æ ¼å¼ [x, y, w, h]"""
    cx_norm, cy_norm, w_norm, h_norm = box_np

    w_pixel = w_norm * img_width
    h_pixel = h_norm * img_height
    x_pixel = (cx_norm * img_width) - (w_pixel / 2)
    y_pixel = (cy_norm * img_height) - (h_pixel / 2)

    # è¾¹ç•Œæ£€æŸ¥
    x_pixel = max(0, x_pixel)
    y_pixel = max(0, y_pixel)
    w_pixel = min(w_pixel, img_width - x_pixel)
    h_pixel = min(h_pixel, img_height - y_pixel)

    if w_pixel > 5 and h_pixel > 5:
        return [float(x_pixel), float(y_pixel), float(w_pixel), float(h_pixel)]
    return None


def calculate_iou(box1, box2):
    """è®¡ç®—ä¸¤ä¸ªæ¡†çš„IoU"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[0] + box1[2], box2[0] + box2[2])
    y2 = min(box1[1] + box1[3], box2[1] + box2[3])

    if x2 <= x1 or y2 <= y1:
        return 0.0

    intersection = (x2 - x1) * (y2 - y1)
    area1 = box1[2] * box1[3]
    area2 = box2[2] * box2[3]
    union = area1 + area2 - intersection

    return intersection / union if union > 0 else 0.0


# --- æ‰‹åŠ¨APè®¡ç®—å‡½æ•°ï¼ˆæ”¹è¿›ç‰ˆï¼‰---
def calculate_ap_manual(detections, gt_boxes, category_id, iou_threshold=0.5):
    """
    æ‰‹åŠ¨è®¡ç®—APï¼ˆé¿å…ä½¿ç”¨pycocotoolsçš„COCOevalï¼‰
    åŸºäºæˆ‘ä»¬ä¹‹å‰éªŒè¯æˆåŠŸçš„æ–¹æ³•
    """
    if len(detections) == 0 or len(gt_boxes) == 0:
        return 0.0, {}

    # æŒ‰ç½®ä¿¡åº¦æ’åºæ£€æµ‹æ¡†
    sorted_detections = sorted(detections, key=lambda x: x['score'], reverse=True)

    true_positives = 0
    false_positives = 0
    used_gts = set()  # è·Ÿè¸ªå·²åŒ¹é…çš„çœŸå®æ¡†
    all_precisions = []  # å­˜å‚¨æ¯ä¸ªæ£€æµ‹ç‚¹çš„ç²¾ç¡®ç‡

    # ä¸ºæ¯ä¸ªæ£€æµ‹è®¡ç®—åŒ¹é…çŠ¶æ€
    for i, det in enumerate(sorted_detections):
        det_box = det['bbox']
        best_iou = 0
        best_gt_idx = -1

        # æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„çœŸå®æ¡†
        for j, gt_box in enumerate(gt_boxes):
            if j in used_gts:
                continue

            iou = calculate_iou(det_box, gt_box)
            if iou > best_iou:
                best_iou = iou
                best_gt_idx = j

        # åˆ¤æ–­æ˜¯å¦åŒ¹é…
        if best_iou > iou_threshold and best_gt_idx != -1:
            true_positives += 1
            used_gts.add(best_gt_idx)
        else:
            false_positives += 1

        # è®¡ç®—å½“å‰çš„ç²¾ç¡®ç‡
        current_precision = true_positives / (true_positives + false_positives) if (
                                                                                               true_positives + false_positives) > 0 else 0
        all_precisions.append(current_precision)

    # è®¡ç®—APï¼ˆæ‰€æœ‰ç²¾ç¡®ç‡çš„å¹³å‡å€¼ï¼‰
    if all_precisions:
        ap = sum(all_precisions) / len(all_precisions)

        # è®¡ç®—å…¶ä»–ç»Ÿè®¡æŒ‡æ ‡
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / len(gt_boxes) if len(gt_boxes) > 0 else 0
        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        stats = {
            'ap': ap,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'true_positives': true_positives,
            'false_positives': false_positives,
            'total_detections': len(detections),
            'total_gt': len(gt_boxes),
            'matched_rate': true_positives / len(gt_boxes) if len(gt_boxes) > 0 else 0
        }

        return ap, stats

    return 0.0, {}


# --- å¤šæç¤ºé›†æˆå‡½æ•° ---
def run_multi_prompt_detection(image_tensor, category_prompts, img_width, img_height,
                               category_name, box_threshold=0.1, text_threshold=0.1):
    """ä½¿ç”¨å¤šä¸ªPromptè¿è¡Œæ£€æµ‹"""
    all_detections = []

    for prompt_text in category_prompts:
        boxes, logits, phrases = predict(
            model=model,
            image=image_tensor,
            caption=prompt_text,
            box_threshold=box_threshold,
            text_threshold=text_threshold,
            device=device
        )

        if len(boxes) > 0:
            boxes_np = boxes.cpu().numpy()

            for box, logit, phrase in zip(boxes_np, logits, phrases):
                # ç±»åˆ«åŒ¹é…æ£€æŸ¥
                phrase_lower = phrase.lower()
                category_lower = category_name.lower()

                # æ‰©å±•çš„åŒ¹é…é€»è¾‘
                is_match = False
                if category_lower in phrase_lower:
                    is_match = True
                elif category_lower == "person" and (
                        "human" in phrase_lower or "man" in phrase_lower or "woman" in phrase_lower):
                    is_match = True
                elif category_lower == "car" and ("vehicle" in phrase_lower or "automobile" in phrase_lower):
                    is_match = True
                elif category_lower == "chair" and ("seat" in phrase_lower or "furniture" in phrase_lower):
                    is_match = True

                if is_match:
                    converted_box = convert_groundingdino_to_coco(box, img_width, img_height)
                    if converted_box:
                        detection = {
                            "bbox": converted_box,
                            "score": float(logit),
                            "prompt": prompt_text,
                            "phrase": phrase
                        }
                        all_detections.append(detection)

    return all_detections


# --- èåˆç­–ç•¥å®ç° ---
def max_confidence_fusion(detections, iou_threshold=0.5):
    """æœ€å¤§ç½®ä¿¡åº¦èåˆç­–ç•¥"""
    if not detections:
        return []

    # æŒ‰ç½®ä¿¡åº¦æ’åº
    sorted_detections = sorted(detections, key=lambda x: x['score'], reverse=True)
    fused_detections = []

    while sorted_detections:
        # å–æœ€é«˜ç½®ä¿¡åº¦çš„æ£€æµ‹
        best_det = sorted_detections.pop(0)
        fused_detections.append(best_det)

        # ç§»é™¤é‡å æ¡†
        remaining_detections = []
        for det in sorted_detections:
            iou = calculate_iou(best_det['bbox'], det['bbox'])
            if iou < iou_threshold:
                remaining_detections.append(det)

        sorted_detections = remaining_detections

    return fused_detections


def weighted_average_fusion(detections, iou_threshold=0.5):
    """åŠ æƒå¹³å‡èåˆç­–ç•¥"""
    if not detections:
        return []

    clusters = []

    # èšç±»ç›¸ä¼¼çš„æ£€æµ‹æ¡†
    for det in detections:
        matched = False
        for cluster in clusters:
            # æ£€æŸ¥æ˜¯å¦ä¸èšç±»ä¸­çš„ä»»ä½•æ¡†åŒ¹é…
            for cluster_det in cluster['detections']:
                iou = calculate_iou(det['bbox'], cluster_det['bbox'])
                if iou >= iou_threshold:
                    cluster['detections'].append(det)
                    matched = True
                    break
            if matched:
                break

        if not matched:
            clusters.append({'detections': [det]})

    # å¯¹æ¯ä¸ªèšç±»è¿›è¡ŒåŠ æƒå¹³å‡
    fused_detections = []
    for cluster in clusters:
        if cluster['detections']:
            # è®¡ç®—åŠ æƒå¹³å‡æ¡†
            total_weight = sum(d['score'] for d in cluster['detections'])
            weighted_bbox = [0, 0, 0, 0]

            for det in cluster['detections']:
                weight = det['score'] / total_weight
                for i in range(4):
                    weighted_bbox[i] += det['bbox'][i] * weight

            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            avg_score = sum(d['score'] for d in cluster['detections']) / len(cluster['detections'])

            fused_detection = {
                'bbox': weighted_bbox,
                'score': avg_score,
                'prompt': 'weighted_fusion',
                'phrase': 'fused detection',
                'num_sources': len(cluster['detections'])
            }
            fused_detections.append(fused_detection)

    return fused_detections


def nms_fusion(detections, iou_threshold=0.5, score_threshold=0.1):
    """NMSèåˆç­–ç•¥"""
    if not detections:
        return []

    # æŒ‰ç½®ä¿¡åº¦æ’åº
    sorted_detections = sorted(detections, key=lambda x: x['score'], reverse=True)
    keep = []

    while sorted_detections:
        # å–æœ€é«˜ç½®ä¿¡åº¦çš„æ£€æµ‹
        current = sorted_detections.pop(0)
        keep.append(current)

        # è®¡ç®—ä¸å‰©ä½™æ¡†çš„IoU
        remaining = []
        for det in sorted_detections:
            iou = calculate_iou(current['bbox'], det['bbox'])
            if iou < iou_threshold:
                remaining.append(det)

        sorted_detections = remaining

    return keep


def wbf_fusion(detections, iou_threshold=0.5, score_threshold=0.1):
    """WBF (Weighted Boxes Fusion) ç­–ç•¥"""
    if not detections:
        return []

    # èšç±»ç›¸ä¼¼çš„æ£€æµ‹æ¡†
    clusters = []
    for det in detections:
        matched = False
        for cluster in clusters:
            # è®¡ç®—ä¸èšç±»ä¸­æ‰€æœ‰æ¡†çš„å¹³å‡IoU
            cluster_ious = []
            for cluster_det in cluster['detections']:
                iou = calculate_iou(det['bbox'], cluster_det['bbox'])
                cluster_ious.append(iou)

            avg_iou = sum(cluster_ious) / len(cluster_ious) if cluster_ious else 0
            if avg_iou >= iou_threshold * 0.5:  # é™ä½é˜ˆå€¼ä»¥å…è®¸æ›´å¤šèåˆ
                cluster['detections'].append(det)
                matched = True
                break

        if not matched:
            clusters.append({'detections': [det]})

    # å¯¹æ¯ä¸ªèšç±»è¿›è¡ŒWBF
    fused_detections = []
    for cluster in clusters:
        if cluster['detections']:
            dets = cluster['detections']

            # è®¡ç®—åŠ æƒæ¡†
            total_score = sum(d['score'] for d in dets)
            weighted_box = [0, 0, 0, 0]

            for det in dets:
                weight = det['score'] / total_score
                for i in range(4):
                    weighted_box[i] += det['bbox'][i] * weight

            # è®¡ç®—èåˆç½®ä¿¡åº¦ï¼ˆè€ƒè™‘æ¥æºæ•°é‡ï¼‰
            avg_score = sum(d['score'] for d in dets) / len(dets)
            fusion_score = avg_score * (1 + 0.1 * len(dets))  # å¥–åŠ±å¤šæºæ£€æµ‹

            fused_detection = {
                'bbox': weighted_box,
                'score': min(fusion_score, 1.0),  # ç¡®ä¿ä¸è¶…è¿‡1.0
                'prompt': 'wbf_fusion',
                'phrase': 'fused detection',
                'num_sources': len(dets)
            }
            fused_detections.append(fused_detection)

    # æŒ‰ç½®ä¿¡åº¦æ’åº
    fused_detections.sort(key=lambda x: x['score'], reverse=True)
    return fused_detections


def apply_fusion_strategy(detections, strategy='max_confidence', **kwargs):
    """åº”ç”¨æŒ‡å®šçš„èåˆç­–ç•¥"""
    if strategy == 'max_confidence':
        return max_confidence_fusion(detections, **kwargs)
    elif strategy == 'weighted_average':
        return weighted_average_fusion(detections, **kwargs)
    elif strategy == 'nms':
        return nms_fusion(detections, **kwargs)
    elif strategy == 'wbf':
        return wbf_fusion(detections, **kwargs)
    else:
        return detections  # é»˜è®¤è¿”å›åŸå§‹æ£€æµ‹


# --- å¯è§†åŒ–å‡½æ•° ---
def visualize_detections_comparison(img_path, fusion_results, gt_boxes, category_name, save_path):
    """å¯è§†åŒ–ä¸åŒèåˆç­–ç•¥çš„ç»“æœæ¯”è¾ƒ"""
    img = Image.open(img_path)

    # åˆ›å»ºå­å›¾ï¼šåŸå§‹ã€å„èåˆç­–ç•¥ã€çœŸå®æ ‡æ³¨
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.ravel()

    # å­å›¾1: çœŸå®æ ‡æ³¨
    ax = axes[0]
    ax.imshow(img)
    for gt_box in gt_boxes:
        rect = patches.Rectangle(
            (gt_box[0], gt_box[1]), gt_box[2], gt_box[3],
            linewidth=2, edgecolor='lime', facecolor='none', alpha=0.7
        )
        ax.add_patch(rect)
    ax.set_title(f"Ground Truth: {len(gt_boxes)} boxes", fontsize=10)
    ax.axis('off')

    # å­å›¾2-5: ä¸åŒèåˆç­–ç•¥
    strategies = ['original', 'max_confidence', 'weighted_average', 'wbf']

    for idx, strategy in enumerate(strategies, 1):
        ax = axes[idx]
        ax.imshow(img)

        if strategy in fusion_results:
            detections = fusion_results[strategy]['detections']

            for det in detections:
                det_box = det['bbox']
                rect = patches.Rectangle(
                    (det_box[0], det_box[1]), det_box[2], det_box[3],
                    linewidth=2, edgecolor='red', facecolor='none', alpha=0.7
                )
                ax.add_patch(rect)

                # æ˜¾ç¤ºåˆ†æ•°
                ax.text(det_box[0], det_box[1] - 5, f"{det['score']:.2f}",
                        bbox=dict(facecolor='red', alpha=0.5), fontsize=8, color='white')

            # æ˜¾ç¤ºç»Ÿè®¡
            stats = fusion_results[strategy].get('stats', {})
            ap = stats.get('ap', 0)
            tp = stats.get('true_positives', 0)
            fp = stats.get('false_positives', 0)

            title = f"{strategy}\nAP: {ap:.3f} | TP: {tp} | FP: {fp}"
            ax.set_title(title, fontsize=10)

        ax.axis('off')

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(strategies) + 1, 6):
        axes[idx].axis('off')

    plt.suptitle(f"Category: {category_name} - Fusion Strategies Comparison", fontsize=14)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  èåˆå¯¹æ¯”å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


# --- å¤šæç¤ºé›†æˆå®éªŒï¼ˆä½¿ç”¨æ‰‹åŠ¨APè®¡ç®—ï¼‰---
def run_multi_prompt_fusion_experiment():
    """è¿è¡Œå¤šæç¤ºé›†æˆå®éªŒ"""
    print("\n" + "=" * 80)
    print("å¤šæç¤ºé›†æˆå®éªŒï¼ˆä½¿ç”¨æ‰‹åŠ¨APè®¡ç®—ï¼‰")
    print("=" * 80)

    all_results = {}
    visualization_data = {}

    for category in TEST_CATEGORIES:
        print(f"\n{'=' * 60}")
        print(f"å¤„ç†ç±»åˆ«: {category}")
        print('=' * 60)

        category_id = category_name_to_id[category.lower()]
        category_prompts = CATEGORY_MULTI_PROMPTS[category]

        # è·å–æµ‹è¯•å›¾ç‰‡
        img_ids = coco.getImgIds(catIds=[category_id])
        if len(img_ids) > 2:  # æµ‹è¯•2å¼ å›¾ç‰‡
            img_ids = img_ids[:2]

        print(f"ä½¿ç”¨ {len(img_ids)} å¼ å›¾ç‰‡")
        print(f"Promptæ•°é‡: {len(category_prompts)}")
        print(f"èåˆç­–ç•¥: {', '.join(FUSION_STRATEGIES.keys())}")
        print(f"APè®¡ç®—æ–¹æ³•: æ‰‹åŠ¨è®¡ç®—ï¼ˆIoUé˜ˆå€¼=0.5ï¼‰")

        category_results = {}

        for img_id in img_ids:
            try:
                img_info = coco.loadImgs(img_id)[0]
                img_path = os.path.join(COCO_ROOT, img_info['file_name'])

                if not os.path.exists(img_path):
                    continue

                print(f"\n  å¤„ç†å›¾ç‰‡: {img_info['file_name']}")

                # è·å–çœŸå®æ ‡æ³¨
                ann_ids = coco.getAnnIds(imgIds=[img_id], catIds=[category_id])
                anns = coco.loadAnns(ann_ids)
                gt_boxes = [ann['bbox'] for ann in anns]
                print(f"    çœŸå®æ ‡æ³¨æ•°: {len(gt_boxes)}")

                # åŠ è½½å›¾ç‰‡
                _, image_tensor = load_image(img_path)
                W, H = img_info['width'], img_info['height']

                # æ­¥éª¤1: ä½¿ç”¨å¤šä¸ªPromptè¿›è¡Œæ£€æµ‹
                all_detections = run_multi_prompt_detection(
                    image_tensor, category_prompts, W, H, category,
                    box_threshold=0.1, text_threshold=0.1
                )

                print(f"    åŸå§‹æ£€æµ‹æ€»æ•°: {len(all_detections)} (æ¥è‡ª{len(category_prompts)}ä¸ªPrompt)")

                if len(all_detections) == 0:
                    print("    æ— æ£€æµ‹ç»“æœï¼Œè·³è¿‡æ­¤å›¾ç‰‡")
                    continue

                # æ­¥éª¤2: åº”ç”¨ä¸åŒèåˆç­–ç•¥
                fusion_results = {}

                # ä¿å­˜åŸå§‹æ£€æµ‹ç»“æœï¼ˆä½¿ç”¨æ‰‹åŠ¨APè®¡ç®—ï¼‰
                ap_score, stats = calculate_ap_manual(all_detections, gt_boxes, category_id, 0.5)
                fusion_results['original'] = {
                    'detections': all_detections,
                    'stats': stats,
                    'ap_score': ap_score
                }

                print(f"    åŸå§‹æ£€æµ‹AP: {ap_score:.4f}")

                # åº”ç”¨æ¯ç§èåˆç­–ç•¥
                for strategy_name, strategy_desc in FUSION_STRATEGIES.items():
                    print(f"    åº”ç”¨èåˆç­–ç•¥: {strategy_name} ({strategy_desc})")

                    fused_detections = apply_fusion_strategy(
                        all_detections.copy(),  # åˆ›å»ºå‰¯æœ¬
                        strategy=strategy_name,
                        iou_threshold=0.5
                    )

                    # ä½¿ç”¨æ‰‹åŠ¨æ–¹æ³•è®¡ç®—AP
                    ap_score, stats = calculate_ap_manual(fused_detections, gt_boxes, category_id, 0.5)

                    fusion_results[strategy_name] = {
                        'detections': fused_detections,
                        'stats': stats,
                        'ap_score': ap_score,
                        'strategy_desc': strategy_desc
                    }

                    print(f"      èåˆåæ£€æµ‹æ•°: {len(fused_detections)}, AP: {ap_score:.4f}")

                # æ­¥éª¤3: è®°å½•ç»“æœ
                img_key = f"img_{img_id}"
                category_results[img_key] = fusion_results

                # æ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”
                save_path = f"fusion_comparison_{category}_{img_id}.png"
                visualize_detections_comparison(img_path, fusion_results, gt_boxes, category, save_path)

                # ä¿å­˜å¯è§†åŒ–æ•°æ®
                if category not in visualization_data:
                    visualization_data[category] = {}
                visualization_data[category][img_key] = {
                    'image_path': img_path,
                    'fusion_results': fusion_results,
                    'gt_boxes': gt_boxes,
                    'visualization_path': save_path
                }

            except Exception as e:
                print(f"  å¤„ç†å›¾ç‰‡ {img_id} å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue

        all_results[category] = category_results

    return all_results, visualization_data


# --- åˆ†æèåˆç­–ç•¥æ•ˆæœï¼ˆä½¿ç”¨æ‰‹åŠ¨APè®¡ç®—ç»“æœï¼‰---
def analyze_fusion_strategies(all_results, output_file="fusion_analysis.md"):
    """åˆ†æä¸åŒèåˆç­–ç•¥çš„æ•ˆæœ"""
    print("\n" + "=" * 80)
    print("èåˆç­–ç•¥æ•ˆæœåˆ†æï¼ˆåŸºäºæ‰‹åŠ¨APè®¡ç®—ï¼‰")
    print("=" * 80)

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# å¤šæç¤ºé›†æˆèåˆç­–ç•¥æ•ˆæœåˆ†æ\n\n")

        f.write("## å®éªŒæ¦‚è¿°\n\n")
        f.write("æœ¬å®éªŒè¯„ä¼°äº†4ç§ä¸åŒçš„æ£€æµ‹èåˆç­–ç•¥åœ¨å¤šæç¤ºé›†æˆä¸­çš„æ•ˆæœã€‚\n")
        f.write("**æ³¨æ„ï¼šæ‰€æœ‰APè®¡ç®—å‡ä½¿ç”¨æ‰‹åŠ¨æ–¹æ³•ï¼Œé¿å…pycocotoolsåº“çš„å…¼å®¹æ€§é—®é¢˜**\n\n")

        f.write("**æµ‹è¯•ç±»åˆ«**: " + ", ".join(TEST_CATEGORIES) + "\n")
        f.write("**èåˆç­–ç•¥**:\n")
        for strategy, desc in FUSION_STRATEGIES.items():
            f.write(f"1. **{strategy}**: {desc}\n")
        f.write("\n**APè®¡ç®—æ–¹æ³•**: æ‰‹åŠ¨è®¡ç®—ï¼ˆIoUé˜ˆå€¼=0.5ï¼‰\n")

        # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œåˆ†æ
        for category in TEST_CATEGORIES:
            f.write(f"\n## {category.capitalize()} ç±»åˆ«\n\n")

            if category in all_results:
                category_results = all_results[category]

                # æ”¶é›†æ‰€æœ‰å›¾ç‰‡çš„ç»“æœ
                strategy_aps = {strategy: [] for strategy in ['original'] + list(FUSION_STRATEGIES.keys())}
                strategy_counts = {strategy: [] for strategy in ['original'] + list(FUSION_STRATEGIES.keys())}
                strategy_precisions = {strategy: [] for strategy in ['original'] + list(FUSION_STRATEGIES.keys())}
                strategy_recalls = {strategy: [] for strategy in ['original'] + list(FUSION_STRATEGIES.keys())}

                for img_key, fusion_results in category_results.items():
                    for strategy, result in fusion_results.items():
                        if strategy in strategy_aps:
                            strategy_aps[strategy].append(result.get('ap_score', 0))
                            strategy_counts[strategy].append(len(result.get('detections', [])))

                            stats = result.get('stats', {})
                            strategy_precisions[strategy].append(stats.get('precision', 0))
                            strategy_recalls[strategy].append(stats.get('recall', 0))

                # è®¡ç®—å¹³å‡APå’Œæ£€æµ‹æ•°
                f.write("### æ€§èƒ½å¯¹æ¯”\n\n")
                f.write("| ç­–ç•¥ | å¹³å‡AP@0.5 | ç›¸å¯¹æå‡ | å¹³å‡æ£€æµ‹æ•° | å¹³å‡ç²¾ç¡®ç‡ | å¹³å‡å¬å›ç‡ |\n")
                f.write("|------|------------|----------|------------|------------|------------|\n")

                baseline_ap = np.mean(strategy_aps['original']) if strategy_aps['original'] else 0

                for strategy in ['original'] + list(FUSION_STRATEGIES.keys()):
                    if strategy_aps[strategy]:
                        avg_ap = np.mean(strategy_aps[strategy])
                        avg_count = np.mean(strategy_counts[strategy])
                        avg_precision = np.mean(strategy_precisions[strategy]) if strategy_precisions[strategy] else 0
                        avg_recall = np.mean(strategy_recalls[strategy]) if strategy_recalls[strategy] else 0

                        if strategy == 'original':
                            rel_improvement = 0
                        else:
                            rel_improvement = ((avg_ap - baseline_ap) / baseline_ap * 100) if baseline_ap > 0 else 0

                        improvement_symbol = ""
                        if rel_improvement > 5:
                            improvement_symbol = "ğŸ“ˆ"
                        elif rel_improvement < -5:
                            improvement_symbol = "ğŸ“‰"

                        f.write(
                            f"| {strategy} | {avg_ap:.4f} | {rel_improvement:+.1f}% {improvement_symbol} | {avg_count:.1f} | {avg_precision:.3f} | {avg_recall:.3f} |\n")

                f.write("\n### ç­–ç•¥åˆ†æ\n\n")

                # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
                best_strategy = None
                best_ap = 0
                for strategy in FUSION_STRATEGIES.keys():
                    if strategy_aps.get(strategy):
                        avg_ap = np.mean(strategy_aps[strategy])
                        if avg_ap > best_ap:
                            best_ap = avg_ap
                            best_strategy = strategy

                if best_strategy:
                    f.write(f"1. **æœ€ä½³ç­–ç•¥**: **{best_strategy}** (å¹³å‡AP={best_ap:.4f})\n")
                    f.write(
                        f"2. ç›¸å¯¹äºåŸå§‹æ£€æµ‹ï¼Œ{best_strategy}ç­–ç•¥æå‡äº†{((best_ap - baseline_ap) / baseline_ap * 100 if baseline_ap > 0 else 0):.1f}%\n")

                # ç­–ç•¥ç‰¹ç‚¹åˆ†æ
                f.write("\n3. **å„ç­–ç•¥ç‰¹ç‚¹**:\n")
                f.write("   - **max_confidence**: ä¿ç•™æœ€é«˜ç½®ä¿¡åº¦çš„æ£€æµ‹ï¼Œå‡å°‘å†—ä½™æ¡†\n")
                f.write("   - **weighted_average**: èåˆç›¸ä¼¼æ£€æµ‹ï¼Œæé«˜å®šä½ç²¾åº¦\n")
                f.write("   - **nms**: æ ‡å‡†éæå¤§å€¼æŠ‘åˆ¶ï¼Œå¹³è¡¡ç²¾åº¦å’Œå¬å›\n")
                f.write("   - **wbf**: åŠ æƒæ¡†èåˆï¼Œè€ƒè™‘å¤šæºä¿¡æ¯ï¼Œé€šå¸¸æ€§èƒ½æœ€ä½³\n")

                f.write("\n---\n")

    print(f"èåˆç­–ç•¥åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


# --- ç”Ÿæˆç»¼åˆæŠ¥å‘Š ---
def generate_fusion_summary(all_results, output_file="fusion_summary.json"):
    """ç”Ÿæˆèåˆå®éªŒæ‘˜è¦"""
    summary = {
        'test_categories': TEST_CATEGORIES,
        'fusion_strategies': FUSION_STRATEGIES,
        'ap_calculation_method': 'manual_calculation_iou_0.5',
        'category_results': {},
        'overall_best_strategy': None,
        'key_findings': []
    }

    # æ”¶é›†å„ç±»åˆ«çš„æœ€ä½³ç­–ç•¥
    category_best_strategies = {}

    for category in TEST_CATEGORIES:
        if category in all_results:
            category_results = all_results[category]

            # è®¡ç®—å„ç­–ç•¥çš„å¹³å‡AP
            strategy_aps = {}
            strategy_details = {}

            for strategy in ['original'] + list(FUSION_STRATEGIES.keys()):
                aps = []
                precisions = []
                recalls = []
                counts = []

                for img_results in category_results.values():
                    if strategy in img_results:
                        result = img_results[strategy]
                        aps.append(result.get('ap_score', 0))

                        stats = result.get('stats', {})
                        precisions.append(stats.get('precision', 0))
                        recalls.append(stats.get('recall', 0))
                        counts.append(len(result.get('detections', [])))

                if aps:
                    strategy_aps[strategy] = np.mean(aps)
                    strategy_details[strategy] = {
                        'avg_ap': np.mean(aps),
                        'avg_precision': np.mean(precisions) if precisions else 0,
                        'avg_recall': np.mean(recalls) if recalls else 0,
                        'avg_detections': np.mean(counts) if counts else 0,
                        'num_samples': len(aps)
                    }

            # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
            if strategy_aps:
                best_strategy = max(strategy_aps.items(), key=lambda x: x[1])[0]
                best_ap = strategy_aps[best_strategy]

                summary['category_results'][category] = {
                    'best_strategy': best_strategy,
                    'best_ap': best_ap,
                    'all_strategy_details': strategy_details
                }

                category_best_strategies[category] = (best_strategy, best_ap)

    # æ‰¾å‡ºæ€»ä½“æœ€ä½³ç­–ç•¥
    if category_best_strategies:
        # è®¡ç®—å„ç­–ç•¥åœ¨æ‰€æœ‰ç±»åˆ«ä¸­çš„å¹³å‡AP
        strategy_avg_aps = {}
        for strategy in FUSION_STRATEGIES.keys():
            aps = []
            for category, (best_strategy, best_ap) in category_best_strategies.items():
                if best_strategy == strategy:
                    aps.append(best_ap)

            if aps:
                strategy_avg_aps[strategy] = np.mean(aps)

        if strategy_avg_aps:
            overall_best = max(strategy_avg_aps.items(), key=lambda x: x[1])[0]
            summary['overall_best_strategy'] = {
                'strategy': overall_best,
                'avg_ap': strategy_avg_aps[overall_best],
                'description': FUSION_STRATEGIES.get(overall_best, ''),
                'categories_count': sum(1 for _, (s, _) in category_best_strategies.items() if s == overall_best)
            }

    # å…³é”®å‘ç°
    summary['key_findings'] = [
        "å¤šæç¤ºé›†æˆèƒ½æ˜¾è‘—æé«˜æ£€æµ‹ç¨³å®šæ€§ï¼ˆåŸºäºæ‰‹åŠ¨APè®¡ç®—éªŒè¯ï¼‰",
        "ä¸åŒèåˆç­–ç•¥åœ¨ä¸åŒç±»åˆ«ä¸Šè¡¨ç°ä¸åŒï¼ŒWBFé€šå¸¸è¡¨ç°æœ€ä½³",
        "èåˆåæ£€æµ‹æ•°é‡é€šå¸¸å‡å°‘ï¼Œä½†æ£€æµ‹è´¨é‡ï¼ˆAPï¼‰æé«˜",
        "æ‰‹åŠ¨APè®¡ç®—æ–¹æ³•é¿å…äº†pycocotoolsåº“çš„å…¼å®¹æ€§é—®é¢˜",
        "åŠ æƒå¹³å‡å’ŒWBFç­–ç•¥èƒ½æœ‰æ•ˆåˆ©ç”¨å¤šPromptä¿¡æ¯"
    ]

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"èåˆå®éªŒæ‘˜è¦å·²ä¿å­˜åˆ°: {output_file}")
    return summary


# --- éªŒè¯æ‰‹åŠ¨APè®¡ç®—æ–¹æ³• ---
def validate_manual_ap_calculation():
    """éªŒè¯æ‰‹åŠ¨APè®¡ç®—æ–¹æ³•çš„æ­£ç¡®æ€§"""
    print("\n" + "=" * 80)
    print("éªŒè¯æ‰‹åŠ¨APè®¡ç®—æ–¹æ³•")
    print("=" * 80)

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¡ˆä¾‹
    test_gt_boxes = [[100, 100, 50, 50]]  # ä¸€ä¸ªçœŸå®æ¡†

    # æµ‹è¯•æ¡ˆä¾‹1: å®Œç¾åŒ¹é…
    perfect_detections = [{
        'bbox': [100, 100, 50, 50],
        'score': 0.9,
        'prompt': 'test',
        'phrase': 'test'
    }]

    ap1, stats1 = calculate_ap_manual(perfect_detections, test_gt_boxes, 1, 0.5)
    print(f"æµ‹è¯•1 - å®Œç¾åŒ¹é…:")
    print(f"  AP: {ap1:.4f} (åº”ä¸º1.0)")
    print(f"  ç²¾ç¡®ç‡: {stats1.get('precision', 0):.4f} (åº”ä¸º1.0)")
    print(f"  å¬å›ç‡: {stats1.get('recall', 0):.4f} (åº”ä¸º1.0)")

    # æµ‹è¯•æ¡ˆä¾‹2: ä¸åŒ¹é…
    bad_detections = [{
        'bbox': [200, 200, 50, 50],  # ä¸é‡å 
        'score': 0.9,
        'prompt': 'test',
        'phrase': 'test'
    }]

    ap2, stats2 = calculate_ap_manual(bad_detections, test_gt_boxes, 1, 0.5)
    print(f"\næµ‹è¯•2 - ä¸åŒ¹é…:")
    print(f"  AP: {ap2:.4f} (åº”ä¸º0.0)")
    print(f"  ç²¾ç¡®ç‡: {stats2.get('precision', 0):.4f} (åº”ä¸º0.0)")

    # æµ‹è¯•æ¡ˆä¾‹3: éƒ¨åˆ†åŒ¹é…
    partial_detections = [
        {'bbox': [110, 110, 40, 40], 'score': 0.8, 'prompt': 'test', 'phrase': 'test'},  # é«˜IoU
        {'bbox': [200, 200, 50, 50], 'score': 0.9, 'prompt': 'test', 'phrase': 'test'}  # ä¸åŒ¹é…
    ]

    ap3, stats3 = calculate_ap_manual(partial_detections, test_gt_boxes, 1, 0.5)
    print(f"\næµ‹è¯•3 - éƒ¨åˆ†åŒ¹é…:")
    print(f"  AP: {ap3:.4f} (åº”ä»‹äº0-1ä¹‹é—´)")
    print(f"  ç²¾ç¡®ç‡: {stats3.get('precision', 0):.4f}")
    print(f"  å¬å›ç‡: {stats3.get('recall', 0):.4f}")

    return ap1 > 0.99 and ap2 < 0.01  # éªŒè¯åŸºæœ¬é€»è¾‘


# --- ä¸»ç¨‹åº ---
if __name__ == "__main__":
    print("Grounding DINO å¤šæç¤ºé›†æˆå®éªŒ")
    print("=" * 80)

    # éªŒè¯æ‰‹åŠ¨APè®¡ç®—æ–¹æ³•
    ap_valid = validate_manual_ap_calculation()
    if not ap_valid:
        print("\nè­¦å‘Šï¼šæ‰‹åŠ¨APè®¡ç®—éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­å®éªŒ...")
    else:
        print("\nâœ“ æ‰‹åŠ¨APè®¡ç®—éªŒè¯é€šè¿‡")

    # è¿è¡Œå¤šæç¤ºé›†æˆå®éªŒ
    all_results, visualization_data = run_multi_prompt_fusion_experiment()

    # åˆ†æèåˆç­–ç•¥æ•ˆæœ
    analyze_fusion_strategies(all_results, "fusion_strategy_analysis.md")

    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    summary = generate_fusion_summary(all_results, "fusion_experiment_summary.json")

    # è¾“å‡ºå®éªŒæ€»ç»“
    print("\n" + "=" * 80)
    print("å®éªŒæ€»ç»“")
    print("=" * 80)

    print(f"\nå®éªŒå®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
    print("1. èåˆç­–ç•¥åˆ†æ: fusion_strategy_analysis.md")
    print("2. å®éªŒæ‘˜è¦: fusion_experiment_summary.json")
    print("3. å¯è§†åŒ–å¯¹æ¯”å›¾: fusion_comparison_*.png")

    if summary.get('overall_best_strategy'):
        best = summary['overall_best_strategy']
        print(f"\næ€»ä½“æœ€ä½³èåˆç­–ç•¥: {best['strategy']}")
        print(f"æè¿°: {best['description']}")
        print(f"å¹³å‡AP: {best['avg_ap']:.4f}")
        print(f"åœ¨ {best['categories_count']}/{len(TEST_CATEGORIES)} ä¸ªç±»åˆ«ä¸­è¡¨ç°æœ€ä½³")

    print(f"\nå„ç±»åˆ«æœ€ä½³ç­–ç•¥:")
    for category in TEST_CATEGORIES:
        if category in summary.get('category_results', {}):
            result = summary['category_results'][category]
            print(f"  {category}: {result['best_strategy']} (AP={result['best_ap']:.4f})")

    print(f"\nå…³é”®å‘ç°:")
    for i, finding in enumerate(summary.get('key_findings', []), 1):
        print(f"  {i}. {finding}")

    print("\n" + "=" * 80)
    print("å¤šæç¤ºé›†æˆå®éªŒå®Œæˆï¼")
    print("=" * 80)