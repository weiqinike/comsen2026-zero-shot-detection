基于GroundingDINO的实验报告

一.GroundingDINO简介

​	Grounding DINO 是一个先进的开放集目标检测模型，它能根据自然语言描述来识别和定位图像中的任何物体。它结合了强大的视觉检测架构与语言理解能力，实现了出色的零样本迁移性能，是连接视觉与语言任务的重要工具。

------

二.GroundingDINO基线复现（批量处理COCO数据集）

1.我先通过对单张图片检测来验证模型能否加载成功，其中一张检测结果如下：（box阈值=0.15，text阈值=0.2）<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\单张图片inference检测结果\Figure_1（box=0.15，text=0.2）.png" style="zoom:72%;" />

​	说明模型能够正常加载。我又分别改变了box和text的阈值，得到了一组检测结果，发现阈值不同，检测结果也不同（阈值越低，检测结果越精准）。这也是我后续批量处理COCO数据集时调整模型检测精准度的一个思路。

2.第一次检测中问题如下：

- 框选物体和预测类别的准确度极低——问题在于只采取了COCO数据集的前20个类别，后面通过将COCO类别按语义分组并且在分组检测后整合来提高检测的准确度，同时使用NMS去除重复框
- 无法生成检测结果——python和JSON格式不符，后续检测已添加格式转换代码解决该问题

3.第二次检测（总共50张图片）其中一张可视化案例如下所示：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\检测结果\第二次检测\可视化案例1\detection_vis_37777.jpg" style="zoom:50%;" />

​	问题如下：

- 未知类别比例高达35.7%——说明模型无法识别这些物体的类别或文本提示与检测结果不匹配

- 类别分布不均衡——检测到很多鸟和飞机，但在COCO室内/城市场景中不应该出现这么多，可能包含大量误检或者文本提示理解有问题

- 大部分检测置信度偏低，很多检测可能在0.2-0.4低信度区间，分布图如下：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\可视化置信度分布1.png" style="zoom:72%;" />

  我尝试从优化文本提示策略入手：将图片中的场景分为indoor、street、nature和mixed四种场景，再通过场景检测自动选择提示词，比如室内场景中可能有家具和电子产品，而街景中可能有交通工具及设施。

  同时我优化了分组策略：由于bird误检次数太多，减少动物类别权重；根据检测到的场景，跳过不相关的分组等。

4.第三次检测中未知类别比例大幅降低至0%，且置信度分布得到极大改善，分布图如下：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\可视化置信度分布2.png" style="zoom:72%;" />

​	同时对物品检测的准确度得到提高，但是经常把“狗”的标签贴在框选的人身上，其中一张可视化案例如下：

<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\检测结果\第三次检测\可视化案例2\detection_vis_397133.jpg" style="zoom:50%;" />

针对“狗”检测次数多，“人”检测次数少的问题，我做出了如下改进：

- 调整类别权重（降低狗的权重，提高人的权重）和阈值（提高狗的阈值，降低人的阈值以提高召回率）
- 进行多尺度任务检测，比如详细提示、部位提示、多人提示
- 增加后处理，过滤过小/过大/长宽比不合理的预测，同时人可以接收较低置信度，但动物需要较高置信度

5.第四次检测中低置信度检测过多，高置信度检测稀少，平均较低，分布图如下：![]()<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\可视化置信度分布3.png" alt="可视化置信度分布3" style="zoom:72%;" />

​	同时我用visualize（mAP）.py对评测后的结果进行分析，图表如下所示：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第一次运行\clear_evaluation_charts.png" style="zoom: 50%;" />

由图可知，AP、AP50、AP75=1.24e-04，数值非常低，分析如下：

- 注意力资源被person抢占 ——增加了person的权重后，模型更关注person，但模型的总注意力资源有限，导致对其他物体的关注度下降
- unknown的比例再次大幅升高——阈值设置不合理，当前阈值0.3太低了，提高person权重后，非person物体的置信度下降，这些低于阈值的检测就被归为unknown

于是我又作出了如下几点改进：

- 动态阈值调整——关于类别，person阈值较低，提高召回，dog阈值较高，减少误检；关于场景，降低室内场景的阈值，提高室外场景的阈值
- 平衡注意力资源——进行分阶段检测（第一阶段专门检测person，第二阶段检测场景相关物体），不同阶段使用不同的置信度，避免person权重过高压制其他物体
- 未知检测重新分类——对置信度较低的常见物体，不直接标记为unknown而是low_confidence，基于位置、大小、形状等判断可能的类别

6.再次进行检测后发现，人的检测准确度仍保持较高，框选的准确度也在提高，但是识别类别的准确度仍然较低，即仍存在“过度person，忽略其他物体的准确分类”问题。

​	这些问题本质在于GroundingDINO模型在“文本-图像对齐”这一核心能力上存在局限性：

​	GroundingDINO这类模型依赖于理解文本描述（如“一只棕色的狗”）并将其与图像中的视觉特征进行关联如果模型在训练时对这种特定组合的学习不够充分或者泛化能力不足，就会在遇到类似但不完全相同的场景时出错。这些问题可能通过融合其他目标检测模型（如YOLO）的检测结果得到改善。

------

二.零样本设置与数据集

1.零样本设定：选择MS COCO2017数据集，使用65seen/15unseen的经典划分

COCO数据集全部80个类别：

```
coco_classes = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',
    'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',
    'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',
    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',
    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',
    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',
    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',
    'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',
    'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]
```

unseen类别：

```
unseen_classes = [
    'toaster', 'hair drier', 'mouse', 'microwave', 'scissors',
    'oven', 'clock', 'book', 'refrigerator', 'toothbrush',
    'vase', 'remote', 'keyboard', 'cell phone', 'sink'
]
```

2.实验设计：通过65/15（seen/unseen）的数据集划分，在ZeroShotCOCODateset中定义了seen_classes和unseen_classes，并将它们映射为seen_ids和unseen_ids；同时，进行评测隔离，即在evaluate函数中，根据mode（‘seen’，‘unseen’，‘all’）来过滤预测结果和真实标注，比如当mode=‘seen’时，只计算seen_ids对应的AP。

3.第一次检测（用20张图片小规模评测）中，总检测框数、匹配预测数和有效预测数差距很大，并且AP为0，分析可能的原因如下：

- 边界框匹配问题——模型预测的边界框与真实边界框没有重叠（loU=0）或者loU低于阈值（0.5）
- 类别映射问题——匹配预测数129但有效预测数只有13，说明多数预测在类别映射后被过滤掉了
- 置信度过低——预测的置信度低，被COCOeval过滤

4.经过几次小规模检测后发现AP为0的关键在于Grounding DINO返回的时归一化坐标无法与像素坐标匹配，于是我进行了边界框格式转换。

​	修复后第二次检测产生了有效结果，结果如下：

```
{
  "config": {
    "coco_root": "C:\\Users\\24344\\GroundingDINO\\weights\\coco\\val2017\\val_images",
    "ann_file": "C:\\Users\\24344\\GroundingDINO\\weights\\coco\\annotations\\annotations_images\\instances_val2017.json",
    "model_config": "C:\\Users\\24344\\GroundingDINO\\groundingdino\\config\\GroundingDINO_SwinT_OGC.py",
    "model_checkpoint": "C:\\Users\\24344\\GroundingDINO\\weights\\groundingdino_swint_ogc.pth",
    "device": "cpu",
    "box_threshold": 0.15,
    "text_threshold": 0.1,
    "test_size": 20
  },
  "all_classes": {
    "AP": 0.17621336762836845,
    "AP50": 0.16606468435197105,
    "AP75": 0.12491856307409216,
    "AP_s": 0.11805026656511802,
    "AP_m": 0.30025494546587955,
    "AP_l": 0.2890109323432343,
    "mode": "all",
    "num_predictions": 159,
    "num_images": 20
  },
  "seen_classes": {
    "AP": 0.20825216174261724,
    "AP50": 0.19625826332505666,
    "AP75": 0.14763102908756345,
    "AP_s": 0.13344812742143775,
    "AP_m": 0.4062272791597195,
    "AP_l": 0.33029820839226776,
    "mode": "seen",
    "num_predictions": 159,
    "num_images": 20
  },
  "unseen_classes": {
    "AP": 0.5453402483105454,
    "AP50": 0.5573628791450572,
    "AP75": 0.3638220964953638,
    "AP_s": 0.4166666666666666,
    "AP_m": 0.6780459295929593,
    "AP_l": 0.31249999999999994,
    "mode": "unseen",
    "num_predictions": 129,
    "num_images": 20
  }
}
```

分析可得：

（1）整体性能表现：AP=0.176，对于零样本检测是合理的

- AP@[0.5:0.95]=0.176，比较合理

- AP@0.5=0.166，在loU=0.5时的平均精度

- AP@0.75=0.125，在loU=0.75时的平均精度

  说明模型定位比较准确

（2）seen与unseen对比：seen类别AP=0.208，unseen类别AP=0.545

​	正常来说应该是seen类别的AP比unseen高，但是本次检测结果却是相反的，分析可能的原因如下：

- unseen类别更容易检测——特征比较明显（如keyboard、cell phone、book、refrigerator等），背景简单（通常出现在室内环境中），尺寸适中（不像"person"那样变化很大）

- seenibie包含更多困难样本——小目标（unseen类别的小、中目标检测均优于seen），遮挡目标（person、car在拥挤场景中），尺寸变化大

  本次检测中unseen类别表现优异，说明模型的泛化能力较强；seen类别表现有待提高，后续检测通过改变阈值和提示来提高seen的AP。

5.第三次检测中，我增加了结果的可视化，并对整个数据集前500张图片进行了评测，结果如下：

```
{
  "config": {
    "coco_root": "C:\\Users\\24344\\GroundingDINO\\weights\\coco\\val2017\\val_images",
    "ann_file": "C:\\Users\\24344\\GroundingDINO\\weights\\coco\\annotations\\annotations_images\\instances_val2017.json",
    "model_config": "C:\\Users\\24344\\GroundingDINO\\groundingdino\\config\\GroundingDINO_SwinT_OGC.py",
    "model_checkpoint": "C:\\Users\\24344\\GroundingDINO\\weights\\groundingdino_swint_ogc.pth",
    "device": "cpu",
    "box_threshold": 0.2,
    "text_threshold": 0.15,
    "nms_threshold": 0.5,
    "apply_nms": true,
    "text_prompt_style": "a clear photo of a {cls}",
    "total_images": 500,
    "max_images": 500
  },
  "all_classes": {
    "AP": 0.08104719114643974,
    "AP50": 0.08290005120278336,
    "AP75": 0.06777849095998217,
    "AP_s": 0.037916291629162914,
    "AP_m": 0.07202032037720187,
    "AP_l": 0.14314169125817422,
    "mode": "all",
    "num_predictions": 312,
    "num_images": 500
  },
  "seen_classes": {
    "AP": 0.09850350923951909,
    "AP50": 0.10075544684645978,
    "AP75": 0.08237693516674754,
    "AP_s": 0.0454995499549955,
    "AP_m": 0.08802483601658005,
    "AP_l": 0.17468138594217872,
    "mode": "seen",
    "num_predictions": 312,
    "num_images": 500
  },
  "unseen_classes": {
    "AP": 0.17415374997831284,
    "AP50": 0.18557802821233782,
    "AP75": 0.12913126888302712,
    "AP_s": 0.15575307530753074,
    "AP_m": 0.1505446904580568,
    "AP_l": 0.36831839222595125,
    "mode": "unseen",
    "num_predictions": 260,
    "num_images": 500
  },
  "statistics": {
    "total_predictions": 6681,
    "matched_predictions": 361,
    "visualization_count": 20
  }
}
```

根据以上结果对检测效率进行分析，同时给出两张可视化案例：

- 总预测数：6681个
- 匹配预测数：361个
- 有效预测数：312个

<img src="C:\Users\24344\Desktop\Comsen\groundingdino第二次运行\可视化案例1（成功匹配）.png" style="zoom: 50%;" />

<img src="C:\Users\24344\Desktop\Comsen\groundingdino第二次运行\可视化案例1（未能成功匹配）.png" style="zoom:50%;" />

​	从数据分析可以看出匹配率极低，只有5.4%，可能是类别映射失败、边界框不匹配或者置信度过低等问题。但是第二张可视化案例匹配数很低的原因明显在于模型预测的时候对很多小目标也进行了框选并预测（且大多数是正确的），但是COCO数据集并没有这些小目标的标注，才导致总预测数和匹配预测数相差巨大。因此不能仅仅凭借较低的AP来判断模型预测的准确性。

​	对seen和unseen的性能差异进行分析：

```
AP@[0.5:0.95]: 0.0810
  - Seen类别: 0.0985
  - Unseen类别: 0.1742
AP@0.5: 0.0829
  - Seen类别: 0.1008
  - Unseen类别: 0.1856
```

跟第二次检测的结果一致，unseen类别的AP（0.174）依旧高于seen类别的AP（0.099），我认为还是因为unseen类别特征更明显、更容易识别，也能反应出模型较好的泛化能力。

6.第四次检测，我使用了完整的5000张图片进行检测，但是因为样本容量过大，只进行了all模式的评测，数据结果与可视化案例如下：

```
Average
Precision(AP) @ [IoU = 0.10:0.75 | area = all | maxDets = 100] = 0.067
Average
Precision(AP) @ [IoU = 0.50 | area = all | maxDets = 100] = 0.069
Average
Precision(AP) @ [IoU = 0.75 | area = all | maxDets = 100] = 0.051
Average
Precision(AP) @ [IoU = 0.10:0.75 | area = small | maxDets = 100] = 0.025
Average
Precision(AP) @ [IoU = 0.10:0.75 | area = medium | maxDets = 100] = 0.076
Average
Precision(AP) @ [IoU = 0.10:0.75 | area = large | maxDets = 100] = 0.113
Average
Recall(AR) @ [IoU = 0.10:0.75 | area = all | maxDets = 1] = 0.070
Average
Recall(AR) @ [IoU = 0.10:0.75 | area = all | maxDets = 10] = 0.083
Average
Recall(AR) @ [IoU = 0.10:0.75 | area = all | maxDets = 100] = 0.083
Average
Recall(AR) @ [IoU = 0.10:0.75 | area = small | maxDets = 100] = 0.025
Average
Recall(AR) @ [IoU = 0.10:0.75 | area = medium | maxDets = 100] = 0.093
Average
Recall(AR) @ [IoU = 0.10:0.75 | area = large | maxDets = 100] = 0.147
```

<img src="C:\Users\24344\Desktop\Comsen\groundingdino第二次运行\可视化案例2（未能成功匹配）.png" style="zoom:50%;" />	从结果可以看出，完整数据集检测的AP低于500张图片预测的AP，说明前500张不是代表性样本。可能的问题有：

- 阈值设置过高——匹配率低可能是因为阈值过滤了太多预测，需要大幅度降低阈值，但是从案例中也可以推测是模型检测太多小目标无法匹配原图片标注，导致匹配率过低

- 文本提示不匹配——GroundingDINO可能期望更简单的格式

  后续我认为可以通过调整参数（模型预测时控制小目标的预测）来提高AP。

------

三.提示词（prompt）工程与对比实验

1.实验设计

A.实验变量

（1）自变量：Prompt策略——为每个测试类别设计5种Prompt策略

| 策略类型     | 设计原则      | 示例                    |
| ------------ | ------------- | ----------------------- |
| **纯名称**   | 最简单的类名  | “person”                |
| **模板化**   | 标准描述格式  | “a photo of a person”   |
| **详细描述** | 添加属性信息  | "a human person"        |
| **上下文化** | 包含场景信息  | "a person in the scene" |
| **动作描述** | 描述状态/动作 | "a person standing"     |

（2）因变量：性能指标

- 主要指标：AP@0.5（平均精度，IoU阈值=0.5）
- 辅助指标：精准率、召回率、F1分数
- 过程指标：检测框数量、匹配数

（3）控制变量

- 模型权重：固定使用预训练模型
- 检测阈值：box_threshold=0.1，text_threshold=0.1
- 测试图片：每个类别3张，固定选择
- 评估标准：IoU阈值=0.5

B.测试类别选择

​	选择3个具有代表性的COCO类别：

| 类别   | 选择理由                 | 测试难度 |
| ------ | ------------------------ | -------- |
| person | 最常见类别，验证通用性   | 中等     |
| car    | 结构化物体，验证形状识别 | 容易     |
| chair  | 家具类，验证类别泛化     | 中等     |

C.实验流程：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\c9d64dee41d474959f78d513e828ce92.png" style="zoom: 33%;" />

2.三个类别的定量对比表如下：

（1）person类别

| Prompt策略 | Prompt文本                     | 检测数量 | **AP@0.5** | 精确率 | 召回率 | 排名    |
| ---------- | ------------------------------ | -------- | ---------- | ------ | ------ | ------- |
| detailed   | `a human person`               | 7        | **0.833**  | 0.714  | 0.714  | 🥇 第1名 |
| action     | `a person standing or sitting` | 10       | **0.725**  | 0.500  | 0.714  | 🥈 第2名 |
| template   | `a photo of a person`          | 9        | **0.667**  | 0.444  | 0.571  | 🥉 第3名 |
| context    | `a person in the scene`        | 17       | **0.554**  | 0.294  | 0.714  | 第4名   |
| pure_name  | `person`                       | 31       | **0.407**  | 0.226  | 1.000  | 第5名   |

下面是可视化案例对比：

- pure_name：最差表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_person_pure_name.png" style="zoom:48%;" />

- template：中等表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_person_template.png" style="zoom:48%;" />

- detailed：最佳表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_person_detailed.png" style="zoom:48%;" />

（2）car类别

| Prompt策略 | Prompt文本          | 检测数量 | **AP@0.5** | 精确率 | 召回率 | 排名    |
| ---------- | ------------------- | -------- | ---------- | ------ | ------ | ------- |
| action     | `a parked car`      | 26       | **0.737**  | 0.538  | 0.933  | 🥇 第1名 |
| template   | `a photo of a car`  | 16       | **0.710**  | 0.500  | 0.533  | 🥈 第2名 |
| detailed   | `a car vehicle`     | 28       | **0.663**  | 0.464  | 0.867  | 🥉 第3名 |
| pure_name  | `car`               | 49       | **0.589**  | 0.306  | 1.000  | 第4名   |
| context    | `a car on the road` | 34       | **0.545**  | 0.412  | 0.933  | 第5名   |

- context：最差表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_car_context.png" style="zoom:48%;" />
- detailed：中等表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_car_detailed.png" style="zoom:48%;" />
- action：最佳表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_car_action.png" style="zoom:48%;" />

（3）chair类别

| Prompt策略 | Prompt文本            | 检测数量 | **AP@0.5** | 精确率 | 召回率 | 排名    |
| ---------- | --------------------- | -------- | ---------- | ------ | ------ | ------- |
| template   | `a photo of a chair`  | 26       | **0.323**  | 0.231  | 0.545  | 🥇 第1名 |
| action     | `a chair for sitting` | 47       | **0.316**  | 0.191  | 0.818  | 🥈 第2名 |
| context    | `a chair in the room` | 51       | **0.309**  | 0.176  | 0.818  | 🥉 第3名 |
| pure_name  | `chair`               | 78       | **0.291**  | 0.115  | 0.818  | 第4名   |
| detailed   | `a chair furniture`   | 34       | **0.109**  | 0.206  | 0.636  | 第5名   |

- detailed：最差表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_chair_detailed.png" style="zoom:48%;" />
- context：中等表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_chair_context.png" style="zoom:48%;" />
- template：最佳表现<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\vis_chair_template.png" style="zoom:48%;" />

2.检测结果（JSON文件）

```
{
  "test_categories": [
    "person",
    "car",
    "chair"
  ],
  "overall_results": {
    "person": {
      "average_ap": 0.6371635286994233,
      "max_ap": 0.8333333333333333,
      "min_ap": 0.4068960748696657,
      "num_prompts": 5
    },
    "car": {
      "average_ap": 0.6489955965635025,
      "max_ap": 0.737402661441123,
      "min_ap": 0.5450142812326385,
      "num_prompts": 5
    },
    "chair": {
      "average_ap": 0.2696484409465435,
      "max_ap": 0.3233571983571984,
      "min_ap": 0.10916014960474074,
      "num_prompts": 5
    }
  },
  "best_prompts": {
    "person": {
      "prompt_name": "detailed",
      "prompt_text": "a human person",
      "ap_score": 0.8333333333333333
    },
    "car": {
      "prompt_name": "action",
      "prompt_text": "a parked car",
      "ap_score": 0.737402661441123
    },
    "chair": {
      "prompt_name": "template",
      "prompt_text": "a photo of a chair",
      "ap_score": 0.3233571983571984
    }
  },
  "key_insights": [
    "Prompt工程对zero-shot检测性能有显著影响",
    "包含上下文的Prompt通常优于纯类名",
    "检测质量比检测数量更重要",
    "不同类别可能需要不同的最优Prompt策略"
  ]
}
```

3.关键发现

（1）各类别最佳prompt：

| 类别   | 最佳Prompt策略 | AP@0.5 | 提升幅度 |
| ------ | -------------- | ------ | -------- |
| person | detailed       | 0.833  | 104.8%   |
| car    | action         | 0.737  | 35.3%    |
| chair  | template       | 0.323  | 196.2%   |

（2）整体趋势分析：

- **Prompt策略的重要性**：不同Prompt的AP差异显著，最大提升幅度超过50%
- **检测质量 vs 数量**：检测框数量多不一定代表AP高，关键在于检测质量
- **类别特异性**：不同类别的最佳Prompt策略有所不同

（3）得出相关工程建议

- 推荐prompt格式：

  ```
  # 推荐使用
  best_prompts = {
      "person": "a photo of a person",
      "car": "a car on the road",
      "chair": "a chair in the room"
  }
  ```

- 通用原则：**包含上下文信息**，如"a photo of", "in the scene"；**避免过于简化**，纯类名效果通常较差；**考虑场景信息**，添加场景描述可提高检测质量；**平衡具体性与通用性**，过于具体的描述可能过拟合。

（4）后续可能拓展

- **扩展测试类别**：测试更多COCO类别
- **优化阈值参数**：寻找最佳box_threshold和text_threshold
- **添加后处理**：集成NMS等后处理算法
- **组合Prompt策略**：尝试多Prompt融合
- **跨数据集验证**：在其他数据集上验证结论

4.使用多提示集成（Prompt Ensembling）进行小幅改进：依旧用person、car、chair三个类别评估4种不同的检测融合策略在多提示集成中的效果。

（1）多提示集成架构：每个类别使用十个不同的prompt，包括：纯名称、简单描述、模板、详细描述、上下文、动作、同义词、复数、细分、动态描述。

（2）融合策略：

- **max_confidence**（最大置信度融合）： 保留最高置信度的检测，减少冗余
- **weighted_average**（加权平均融合）： 融合相似检测，提高定位精度
- **nms**（NMS融合）：标准非极大值抑制，平衡精度和召回
- **wbf**（WBF融合）：加权框融合，考虑多源信息

（3）性能对比：

a.person类别：四个策略中wbf策略最佳。

| 策略             | 平均AP@0.5 | 相对提升  | 平均检测数 | 平均精确率 | 平均召回率 |
| ---------------- | ---------- | --------- | ---------- | ---------- | ---------- |
| original         | 0.1541     | +0.0%     | 49.5       | 0.059      | 1.000      |
| max_confidence   | 0.4416     | +186.6% 📈 | 12.0       | 0.245      | 1.000      |
| weighted_average | 0.5451     | +253.8% 📈 | 9.5        | 0.322      | 1.000      |
| nms              | 0.4416     | +186.6% 📈 | 12.0       | 0.245      | 1.000      |
| wbf              | 0.5597     | +263.2% 📈 | 6.0        | 0.333      | 0.625      |

可视化案例如下：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\fusion_comparison_person_458755.png" style="zoom:48%;" />

b.car类别：四个策略中max_confidence策略最佳。

| 策略             | 平均AP@0.5 | 相对提升  | 平均检测数 | 平均精确率 | 平均召回率 |
| ---------------- | ---------- | --------- | ---------- | ---------- | ---------- |
| original         | 0.1727     | +0.0%     | 113.0      | 0.062      | 1.000      |
| max_confidence   | 0.5679     | +228.8% 📈 | 23.0       | 0.269      | 1.000      |
| weighted_average | 0.4531     | +162.3% 📈 | 20.0       | 0.253      | 0.833      |
| nms              | 0.5679     | +228.8% 📈 | 23.0       | 0.269      | 1.000      |
| wbf              | 0.4126     | +138.9% 📈 | 15.5       | 0.260      | 0.667      |

可视化案例如下：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\fusion_comparison_car_184324.png" style="zoom:48%;" />

c.chair类别：四个策略中max_confidence策略和nms策略最佳。

| 策略             | 平均AP@0.5 | 相对提升  | 平均检测数 | 平均精确率 | 平均召回率 |
| ---------------- | ---------- | --------- | ---------- | ---------- | ---------- |
| original         | 0.0226     | +0.0%     | 106.5      | 0.010      | 0.750      |
| max_confidence   | 0.0872     | +286.4% 📈 | 18.0       | 0.058      | 0.750      |
| weighted_average | 0.0454     | +101.1% 📈 | 15.5       | 0.066      | 0.750      |
| nms              | 0.0872     | +286.4% 📈 | 18.0       | 0.058      | 0.750      |
| wbf              | 0.0688     | +205.0% 📈 | 11.0       | 0.094      | 0.750      |

可视化案例如下：![]()<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\fusion_comparison_chair_241668.png" style="zoom:48%;" />

​	从上述结果看。wbf是总体最佳融合策略，平均AP为0.5597.

（3）检测结果（JSON文件）

```
{
  "test_categories": [
    "person",
    "car",
    "chair"
  ],
  "fusion_strategies": {
    "max_confidence": "最大置信度融合",
    "weighted_average": "加权平均融合",
    "nms": "NMS融合",
    "wbf": "WBF融合"
  },
  "ap_calculation_method": "manual_calculation_iou_0.5",
  "category_results": {
    "person": {
      "best_strategy": "wbf",
      "best_ap": 0.5597222222222222,
      "all_strategy_details": {
        "original": {
          "avg_ap": 0.15408925557734476,
          "avg_precision": 0.05889724310776942,
          "avg_recall": 1.0,
          "avg_detections": 49.5,
          "num_samples": 2
        },
        "max_confidence": {
          "avg_ap": 0.44155926629702846,
          "avg_precision": 0.24475524475524477,
          "avg_recall": 1.0,
          "avg_detections": 12.0,
          "num_samples": 2
        },
        "weighted_average": {
          "avg_ap": 0.5451014109347443,
          "avg_precision": 0.3222222222222222,
          "avg_recall": 1.0,
          "avg_detections": 9.5,
          "num_samples": 2
        },
        "nms": {
          "avg_ap": 0.44155926629702846,
          "avg_precision": 0.24475524475524477,
          "avg_recall": 1.0,
          "avg_detections": 12.0,
          "num_samples": 2
        },
        "wbf": {
          "avg_ap": 0.5597222222222222,
          "avg_precision": 0.3333333333333333,
          "avg_recall": 0.625,
          "avg_detections": 6.0,
          "num_samples": 2
        }
      }
    },
    "car": {
      "best_strategy": "max_confidence",
      "best_ap": 0.5678999323181775,
      "all_strategy_details": {
        "original": {
          "avg_ap": 0.17271525379452132,
          "avg_precision": 0.06160835983643798,
          "avg_recall": 1.0,
          "avg_detections": 113.0,
          "num_samples": 2
        },
        "max_confidence": {
          "avg_ap": 0.5678999323181775,
          "avg_precision": 0.26900584795321636,
          "avg_recall": 1.0,
          "avg_detections": 23.0,
          "num_samples": 2
        },
        "weighted_average": {
          "avg_ap": 0.4530644045990073,
          "avg_precision": 0.2531328320802005,
          "avg_recall": 0.8333333333333333,
          "avg_detections": 20.0,
          "num_samples": 2
        },
        "nms": {
          "avg_ap": 0.5678999323181775,
          "avg_precision": 0.26900584795321636,
          "avg_recall": 1.0,
          "avg_detections": 23.0,
          "num_samples": 2
        },
        "wbf": {
          "avg_ap": 0.41255095309782813,
          "avg_precision": 0.26041666666666663,
          "avg_recall": 0.6666666666666667,
          "avg_detections": 15.5,
          "num_samples": 2
        }
      }
    },
    "chair": {
      "best_strategy": "max_confidence",
      "best_ap": 0.08718466994709907,
      "all_strategy_details": {
        "original": {
          "avg_ap": 0.022565983156096595,
          "avg_precision": 0.01035387905891503,
          "avg_recall": 0.75,
          "avg_detections": 106.5,
          "num_samples": 2
        },
        "max_confidence": {
          "avg_ap": 0.08718466994709907,
          "avg_precision": 0.05844155844155844,
          "avg_recall": 0.75,
          "avg_detections": 18.0,
          "num_samples": 2
        },
        "weighted_average": {
          "avg_ap": 0.045378362803890716,
          "avg_precision": 0.06623931623931624,
          "avg_recall": 0.75,
          "avg_detections": 15.5,
          "num_samples": 2
        },
        "nms": {
          "avg_ap": 0.08718466994709907,
          "avg_precision": 0.05844155844155844,
          "avg_recall": 0.75,
          "avg_detections": 18.0,
          "num_samples": 2
        },
        "wbf": {
          "avg_ap": 0.06881941657582684,
          "avg_precision": 0.09401709401709402,
          "avg_recall": 0.75,
          "avg_detections": 11.0,
          "num_samples": 2
        }
      }
    }
  },
  "overall_best_strategy": {
    "strategy": "wbf",
    "avg_ap": 0.5597222222222222,
    "description": "WBF融合",
    "categories_count": 1
  },
  "key_findings": [
    "多提示集成能显著提高检测稳定性（基于手动AP计算验证）",
    "不同融合策略在不同类别上表现不同，WBF通常表现最佳",
    "融合后检测数量通常减少，但检测质量（AP）提高",
    "手动AP计算方法避免了pycocotools库的兼容性问题",
    "加权平均和WBF策略能有效利用多Prompt信息"
  ]
}
```

（4）关键发现：

- 多提示集成能显著提高检测稳定性（基于手动AP计算验证）
- 不同融合策略在不同类别上表现不同，WBF通常表现最佳
- 融合后检测数量通常减少，但检测质量（AP）提高
- 手动AP计算方法避免了pycocotools库的兼容性问题
- 加权平均和WBF策略能有效利用多Prompt信息

（5）失败案例：一开始因为GroundingDINO输出坐标结果和COCO格式不匹配的问题导致IoU和AP极低，尝试了几种坐标转换假设进行对比，三张对比图如下：<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\debug_hypotheses_385029_0.png" alt="debug_hypotheses_385029_0" style="zoom:48%;" />

<img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\debug_hypotheses_458755_1.png" style="zoom:48%;" /><img src="C:\Users\24344\Desktop\Comsen\groundingdino第三次运行\debug_hypotheses_532481_3.png" alt="debug_hypotheses_532481_3" style="zoom:48%;" />

